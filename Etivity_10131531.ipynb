{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4021 - Group Project 2.3\n",
    "\n",
    "### Problem Statement: Change of Survival on the Titanic\n",
    "\n",
    "Classification Problem to predict the chances of a passenger surviving the Titanic journey.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Information\n",
    "\n",
    "####   Source: https://www.kaggle.com/c/titanic \n",
    "\n",
    "#### Context: \n",
    "\"A manifest of data for each passenger on the titanic. With all of the passenger information, we can create and predict the survival of a passenger.\"\n",
    "\n",
    "#### Content: \n",
    "Each row represents a passenger, each column contains passenger information.\n",
    "\n",
    "##### The data set includes information about:\n",
    "\n",
    "- `survival`: Survival (0 = no; 1 = yes)\n",
    "- `class`: Passenger class (1 = first; 2 = second; 3 = third)\n",
    "- `name`: Name\n",
    "- `sex`: Sex\n",
    "- `age`: Age\n",
    "- `sibsp`: Number of siblings/spouses aboard\n",
    "- `parch`: Number of parents/children aboard\n",
    "- `ticket`: Ticket number\n",
    "- `fare`: Passenger fare\n",
    "- `cabin`: Cabin\n",
    "- `embarked`: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- `boat`: Lifeboat (if survived)\n",
    "- `body`: Body number (if did not survive and body was recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanic3.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0b27710fd7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitanic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titanic3.xls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'titanic3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/lib/python3.5/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic3.xls'"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_excel('titanic3.xls', 'titanic3', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking at the whole of the data we can explore it and gain some insights into why certain passengers survived over others and determine some of the main factors or feature vectors that influence the data, we can use this to then train our model and predict the survival of a passenger. \n",
    "\n",
    "* The next section will cover data exploration and insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall chance of survival\n",
    "titanic_df['survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_group = titanic_df.groupby(['pclass','sex']).mean()\n",
    "sex_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From a brief observation of the data we can see that if you were a female. You had a much higher percentage of surviving than being a male. Also the level at which the passenger had a ticket for also influenced the survival. Passengers in the lowest rungs of class 3 were some of the lowest survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I can create a model to train and test the data I must filter out null values / missing data from the dataset. Once this is complete I can split it into training and test sets. Garbage data in will result in gargabge data out for the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that we are missing a lot of values from cabin, boat and body. We're going to drop these columns from the dataset.\n",
    "* home.dest is also missing quite a few but we can default this value to NA.\n",
    "* Age is missing quite a few values so we will have to remove all rows that are missing an age. From the history, we know that younger people were put on lifeboats as a first priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(['body','cabin','boat'], axis=1)\n",
    "titanic_df[\"home.dest\"] = titanic_df[\"home.dest\"].fillna(\"NA\")\n",
    "titanic_df = titanic_df.dropna()\n",
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now all the samples contain the same number of values so the data is ready to be formatted to be inserted for use in an ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, tree, preprocessing, metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split, ShuffleSplit, cross_val_score\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "import seaborn\n",
    "from sklearn.linear_model import Perceptron\n",
    "import itertools\n",
    "\n",
    "def preprocess_titanic_dataset(df):\n",
    "    # Make copy of dataset, set data labels and filter out non useful columns.\n",
    "    processed_df = df.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    processed_df.sex = le.fit_transform(processed_df.sex)\n",
    "    processed_df.embarked = le.fit_transform(processed_df.embarked)\n",
    "    processed_df = processed_df.drop(['name','ticket','home.dest'],axis=1)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = preprocess_titanic_dataset(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_df.drop(['survived'], axis=1).values\n",
    "y = processed_df['survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, normalize = False):\n",
    "    print(cm)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    labels = ['Survived', 'Not Survived']\n",
    "    plt.xticks(tick_marks, labels, rotation = 45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if cm[i, j] > 0:\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.grid()\n",
    "    plt.show(block = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_validator = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0)\n",
    "def test_classifier(clf):\n",
    "    scores =  cross_val_score(clf, X, y, cv=shuffle_validator)\n",
    "    print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "    y_pred = clf.predict(X=X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=\"Survival Rate\")\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "clf_dt = tree.DecisionTreeClassifier(max_depth=10)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "train_score = clf_dt.score (X_train, y_train)\n",
    "print(train_score)\n",
    "clf_dt.score(X_test, y_test)\n",
    "\n",
    "test_classifier(clf_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
    "clf_rf.fit (X_train, y_train)\n",
    "train_score = clf_rf.score (X_train, y_train)\n",
    "print(train_score)\n",
    "clf_rf.score (X_test, y_test)\n",
    "\n",
    "y_pred = clf_rf.predict(X=X_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "test_classifier(clf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "clf_gb.fit (X_train, y_train)\n",
    "train_score = clf_gb.score (X_train, y_train)\n",
    "print(train_score)\n",
    "clf_gb.score (X_test, y_test)\n",
    "y_pred = clf_gb.predict(X=X_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "test_classifier(clf_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "clf_prtn = Perceptron(tol=0.01, random_state=1)\n",
    "clf_prtn.fit (X_train, y_train)\n",
    "train_score = clf_prtn.score (X_train, y_train)\n",
    "test_score = clf_prtn.score (X_test, y_test)\n",
    "print(train_score)\n",
    "y_pred = clf_prtn.predict(X=X_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "scores =  cross_val_score(clf_prtn, X, y, cv =shuffle_validator)\n",
    "print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "eclf = ske.VotingClassifier([('dt', clf_dt), ('rf', clf_rf), ('gb', clf_gb), ('prtn', clf_prtn)])\n",
    "scores =  cross_val_score(eclf, X, y, cv=shuffle_validator)\n",
    "print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
