{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4021 - Project\n",
    "## Group 2.4\n",
    "Gerry Kerley\n",
    "### Dataset used\n",
    "Titanic passenger survival: \n",
    "https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b535943dadd5e5091eaaec7a6e4efc10195c0f16"
   },
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0209cf099f6968e9c9eb6b4e02a7496ce0db7382"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0209cf099f6968e9c9eb6b4e02a7496ce0db7382"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic/train.csv')\n",
    "test = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "train.info()\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af20405f6dc56fee1992459d0dcc6b6bfbdecec7"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([train, test])\n",
    "sns.heatmap(combined_data.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age & Cabin have a lot of missing data.\n",
    "\n",
    "Cabin number is probably not that important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing Age data\n",
    "Check whether the 3 passenger classes have different age distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(x='Pclass',y='Age',data=combined_data,palette='autumn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st class tends to have older passengers so we can use the mean age for each class to fill in the blank ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_ages_with_mean_for_pclass (cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]   \n",
    "          \n",
    "    if pd.isnull(Age): \n",
    "        \n",
    "        if Pclass == 1:            \n",
    "            return np.mean(combined_data[combined_data['Pclass'] == 1 ]['Age'])\n",
    "\n",
    "        elif Pclass == 2:\n",
    "            return np.mean(combined_data[combined_data['Pclass'] == 2 ]['Age'])\n",
    "\n",
    "        else:\n",
    "            return np.mean(combined_data[combined_data['Pclass'] == 3 ]['Age'])\n",
    "\n",
    "    else:\n",
    "        return Age\n",
    "    \n",
    "combined_data['Age'] = combined_data[['Age','Pclass']].apply(fill_missing_ages_with_mean_for_pclass, axis=1)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df326f4035ea0319bbea359da9d6128cc1900828"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=train_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60b528b4d181ca07df1e418a67030352fac9dd98"
   },
   "outputs": [],
   "source": [
    "sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_data,\n",
    "              palette={\"male\": \"green\", \"female\": \"orange\"},\n",
    "              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1474b4e78712dab1b6eb0742911a3e3bc20a2413"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(data):\n",
    "    # Age\n",
    "    data.Age = data.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 20, 25, 40, 65, 120)\n",
    "    categories = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    age_groups = pd.cut(data.Age, bins, labels=categories)\n",
    "    data.Age = age_groups\n",
    "    \n",
    "    # TODO: categorise fares, split name?, cabin numbers?\n",
    "    #data.Fare = data.Fare.fillna(-0.5)\n",
    "    data.fillna(value={'Fare': np.mean(data['Fare'])}, inplace=True)\n",
    "    \n",
    "    # TODO: Convert Pclass to Social Class\n",
    "    \n",
    "    # Drop columns\n",
    "    unwanted_cols = ['Embarked', 'Ticket', 'Name', 'Cabin']\n",
    "    data.drop(unwanted_cols, axis=1, inplace= True)\n",
    "\n",
    "    return data\n",
    "\n",
    "combined_data = prepare_features(combined_data)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15058b67c0bddca4cbd3bd740f6e296cbac16074"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=combined_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a13c4648d7f68e7841a56a3c687e3e0e9f0408c0"
   },
   "source": [
    "### Normalise labels\n",
    "Use SKLearn's LabelEncoder to convert each unique string value into a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a74116096b454a326392e37baf39f2fd3073808a"
   },
   "outputs": [],
   "source": [
    "def encode_features(combined_data):\n",
    "    features = ['Age', 'Sex']\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(combined_data[feature])\n",
    "        combined_data[feature] = le.transform(combined_data[feature])\n",
    "    return combined_data\n",
    "    \n",
    "combined_data = encode_features(combined_data)\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "X = combined_data[features]\n",
    "\n",
    "plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(X.corr(), annot=True, cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7de233bdc873bab7095eb4f2904ac23261763ef1"
   },
   "source": [
    "## Training \n",
    "#### Split the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ee8910d7d81d305ff86ddcf5cc310bff4d0540a"
   },
   "outputs": [],
   "source": [
    "train_data = combined_data[combined_data['Survived'].notnull()]\n",
    "test_data = combined_data[combined_data['Survived'].isnull()]\n",
    "test_data = test_data.drop('Survived', axis=1)\n",
    "\n",
    "X_all = train_data.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y_all = train_data['Survived']\n",
    "\n",
    "test_proportion = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=test_proportion, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de0a66a489f5dd1e35dba88b02b5d0e7e1ba9804"
   },
   "source": [
    "## Machine Learning\n",
    "#### Fit, predict and fine tune the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = log_reg.predict(X_test)\n",
    "lr_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, lr_predictions)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f58d494e31690ea9d885dd5e35018397c52c3493"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c531123ed26b163f1ae7f68d3c02eee7520d444"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(log_reg, X_train, y_train, cv=10)\n",
    "scores.sort()\n",
    "accuracy = scores.mean()\n",
    "\n",
    "print(scores)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbe488c542ad2d23e9fa54282ce3bbf1aa1e9077"
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "parameters = {'n_estimators': [4, 7, 10], \n",
    "              'max_features': ['log2', 'sqrt', 'auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "grid_search = GridSearchCV(rf_clf, parameters, scoring=scorer)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "rf_clf = grid_search.best_estimator_\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3aa3b80f2c19948ebd915f6d10a5f116ab715ffb"
   },
   "outputs": [],
   "source": [
    "rf_predictions = rf_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35a4440a7481f33295c8558c5ddf50d2bdf39865"
   },
   "source": [
    "### Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c685515df03b831872a6a2da5f3e7843df02b82"
   },
   "outputs": [],
   "source": [
    "ids = test_data['PassengerId']\n",
    "\n",
    "predictions = rf_clf.predict(test_data.drop('PassengerId', axis=1))\n",
    "\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "# output.to_csv('titanic/titanic-predictions.csv', index = False)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
