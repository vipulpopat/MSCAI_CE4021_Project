{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Student Name:\n",
    "#Student ID:\n",
    "\n",
    "#Student Name:\n",
    "#Student ID:\n",
    "\n",
    "#Student Name:\n",
    "#Student ID:\n",
    "\n",
    "#Student Name:\n",
    "#Student ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "* SEED : Used as value for functions that take a random seed as an argument. The function of this parameter is to ensure repeatability between runs of the notebook\n",
    "* TEST_SIZE : Used to determine the split of the dataset into a Test set and a Training Set. Needs to be specified as a float between 0.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "TEST_SIZE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Import the UCI Communities and Crimes dataset using Pandas\n",
    "Details on the dataset is available at the following [link](http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Following code is from https://github.com/amclean3695/Communities-and-Crime/blob/master/Communities_and_Crime.ipynb\n",
    "# TODO : See is there any other means for pulling column names from C45 file format\n",
    "#Reads in names from textfile and performs regex to extract the attribute names \n",
    "textfile = open('communities.names','r')\n",
    "filetext = textfile.read()\n",
    "textfile.close()\n",
    "matches = re.findall(r'-{2}\\s(\\w+)\\:{1}', filetext)\n",
    "col_names = matches[2:] #corresponds to the 128 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 128)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('communities.data', header=None, names=col_names)\n",
    "\n",
    "#data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data'\n",
    "#df = pd.read_csv(data_url, header=None)\n",
    "# The above code does not work as PythonAnywhere blocks outgoing connections for free accounts to non-whitelisted sites\n",
    "\n",
    "#print(df.head(5))\n",
    "#dir(df)\n",
    "print(df.shape)\n",
    "#print(df['ViolentCrimesPerPop'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Non-Predictive Attributes\n",
    "\n",
    "Of the 128 attributes loaded, for this dataset it is stated that:\n",
    "\n",
    "Attribute Information: (122 predictive, 5 non-predictive, 1 goal) \n",
    "* state: US state (by number) - not counted as predictive above, but if considered, should be consided nominal (nominal) \n",
    "* county: numeric code for county - not predictive, and many missing values (numeric) \n",
    "* community: numeric code for community - not predictive and many missing values (numeric) \n",
    "* communityname: community name - not predictive - for information only (string) \n",
    "* fold: fold number for non-random 10 fold cross validation, potentially useful for debugging, paired tests - not predictive (numeric) \n",
    "\n",
    "Therefore, the first five columns shall be removed from the dataset. This reduces the total number of columns from 128 to 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 123)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['state', 'county', 'community', 'communityname', 'fold'], axis=1)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViolentCrimesPerPop    0\n",
       "PctNotHSGrad           0\n",
       "PctUnemployed          0\n",
       "PctEmploy              0\n",
       "PctEmplManu            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df.head(5))\n",
    "# From DePy_Talk Noteboook\n",
    "# How much of your data is missing?\n",
    "df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no cells with missing data\n",
    "However, visually inspecting the data, there are cells with \"?\" and this needs to be replaced with \"NaN\" (Not a Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OtherPerCap', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps',\n",
      "       'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop',\n",
      "       'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol',\n",
      "       'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian',\n",
      "       'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz',\n",
      "       'PolicAveOTWorked', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr',\n",
      "       'LemasGangUnitDeploy', 'PolicBudgPerPop'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.replace('?', np.nan)\n",
    "print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LemasSwFTFieldPerPop    1675\n",
       "PctPolicAsian           1675\n",
       "PolicBudgPerPop         1675\n",
       "LemasSwornFT            1675\n",
       "LemasSwFTPerPop         1675\n",
       "LemasSwFTFieldOps       1675\n",
       "LemasTotalReq           1675\n",
       "LemasTotReqPerPop       1675\n",
       "PolicReqPerOffic        1675\n",
       "PolicPerPop             1675\n",
       "RacialMatchCommPol      1675\n",
       "PctPolicBlack           1675\n",
       "PctPolicHisp            1675\n",
       "PctPolicWhite           1675\n",
       "PctPolicMinor           1675\n",
       "PolicCars               1675\n",
       "LemasGangUnitDeploy     1675\n",
       "LemasPctPolicOnPatr     1675\n",
       "OfficAssgnDrugUnits     1675\n",
       "PolicOperBudg           1675\n",
       "PolicAveOTWorked        1675\n",
       "NumKindsDrugsSeiz       1675\n",
       "OtherPerCap                1\n",
       "PctLess9thGrade            0\n",
       "PctPopUnderPov             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 123)\n",
      "1994\n",
      "1675\n",
      "Column  LemasSwornFT 1675\n",
      "Column  LemasSwFTPerPop 1675\n",
      "Column  LemasSwFTFieldOps 1675\n",
      "Column  LemasSwFTFieldPerPop 1675\n",
      "Column  LemasTotalReq 1675\n",
      "Column  LemasTotReqPerPop 1675\n",
      "Column  PolicReqPerOffic 1675\n",
      "Column  PolicPerPop 1675\n",
      "Column  RacialMatchCommPol 1675\n",
      "Column  PctPolicWhite 1675\n",
      "Column  PctPolicBlack 1675\n",
      "Column  PctPolicHisp 1675\n",
      "Column  PctPolicAsian 1675\n",
      "Column  PctPolicMinor 1675\n",
      "Column  OfficAssgnDrugUnits 1675\n",
      "Column  NumKindsDrugsSeiz 1675\n",
      "Column  PolicAveOTWorked 1675\n",
      "Column  PolicCars 1675\n",
      "Column  PolicOperBudg 1675\n",
      "Column  LemasPctPolicOnPatr 1675\n",
      "Column  LemasGangUnitDeploy 1675\n",
      "Column  PolicBudgPerPop 1675\n",
      "(1994, 101)\n"
     ]
    }
   ],
   "source": [
    "#print(df.isnull().sum())\n",
    "print(df.shape)\n",
    "print(df.shape[0])\n",
    "print(df['LemasSwFTFieldPerPop'].isnull().sum())\n",
    "for column in df:\n",
    "    if(df[column].isnull().sum()>=(df.shape[0]/2)):\n",
    "        print(\"Column \", column, df[column].isnull().sum())\n",
    "        df = df.drop([column], axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OtherPerCap            1\n",
       "PctOccupManu           0\n",
       "HispPerCap             0\n",
       "NumUnderPov            0\n",
       "PctPopUnderPov         0\n",
       "PctLess9thGrade        0\n",
       "PctNotHSGrad           0\n",
       "PctBSorMore            0\n",
       "PctUnemployed          0\n",
       "PctEmploy              0\n",
       "PctEmplManu            0\n",
       "PctEmplProfServ        0\n",
       "ViolentCrimesPerPop    0\n",
       "NumIlleg               0\n",
       "MalePctDivorce         0\n",
       "MalePctNevMarr         0\n",
       "FemalePctDiv           0\n",
       "TotalPctDiv            0\n",
       "PersPerFam             0\n",
       "PctFam2Par             0\n",
       "PctKids2Par            0\n",
       "PctYoungKids2Par       0\n",
       "PctTeen2Par            0\n",
       "PctWorkMomYoungKids    0\n",
       "PctOccupMgmtProf       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one missing value remaining but lets impute it for the craic using code from the DePy_Talk notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/IPython/kernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# print(df['OtherPerCap'][130])\n",
    "\n",
    "# # dir(sklearn)\n",
    "# # from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# # imp.fit(df) \n",
    "# # X = pd.DataFrame(data=imp.transform(df) , columns=df.columns)\n",
    "\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# my_imputer = SimpleImputer()\n",
    "\n",
    "#TEMP WORKAROUND\n",
    "# Set to median\n",
    "print(df['OtherPerCap'][130])\n",
    "#print(df['OtherPerCap'].median())\n",
    "#print(df['OtherPerCap'].mean())\n",
    "dir(df['OtherPerCap'])\n",
    "miss_median = df['OtherPerCap'].median()\n",
    "df['OtherPerCap'][130] = miss_median\n",
    "print(df['OtherPerCap'][130])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Before Outlier Removal\n",
      "(1994, 101)\n",
      "Outliers =  110 out of  1994 in ViolentCrimesPerPop Column\n",
      "Shape After Outlier Removal\n",
      "(1884, 101)\n"
     ]
    }
   ],
   "source": [
    "# Store off original dataset without outlier detection and removal\n",
    "dataset = df.values\n",
    "\n",
    "# From DePy_Talk Notebook[1]\n",
    "def find_outliers_tukey(x):\n",
    "    q1 = np.percentile(x, 25)\n",
    "    q3 = np.percentile(x, 75)\n",
    "    iqr = q3-q1\n",
    "    floor = q1 - 1.5*iqr\n",
    "    ceiling = q3 + 1.5*iqr\n",
    "    outlier_indices = list(x.index[(x < floor)|(x > ceiling)])\n",
    "    outlier_values = list(x[outlier_indices])\n",
    "    \n",
    "    return outlier_indices, outlier_values\n",
    "\n",
    "tukey_indices, tukey_values = find_outliers_tukey(df['ViolentCrimesPerPop'])\n",
    "\n",
    "print(\"Shape Before Outlier Removal\")\n",
    "print(df.shape)\n",
    "#print(\"Entry 26\", df['ViolentCrimesPerPop'][26])\n",
    "print(\"Outliers = \",len(tukey_indices), \"out of \",len(df['ViolentCrimesPerPop']), \"in ViolentCrimesPerPop Column\")\n",
    "#print(np.sort(tukey_values))\n",
    "#print(np.sort(tukey_indices))\n",
    "for i in range(len(tukey_indices)):\n",
    "    #print(\"i : \", i, \"Index\", tukey_indices[i], \"Value\", tukey_values[i])\n",
    "    # Drop row containing the outlier\n",
    "    df = df.drop([tukey_indices[i]], axis=0)\n",
    "print(\"Shape After Outlier Removal\")\n",
    "print(df.shape)\n",
    "\n",
    "# Store dataset with outlier\n",
    "tukey_dataset = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split Up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 101)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "X = dataset[:, 0:100]\n",
    "y = dataset[:, 100]\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Dataset\n",
    "TODO ADD DETAILS MPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ul9939245/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ul9939245/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ul9939245/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Scale the dataset\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# Scale the data with respect to the training data set \n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train) \n",
    "\n",
    "X_scaled_train = scaler.transform(X_train) \n",
    "# Scaling the test set using the transform defined by the train set. \n",
    "X_scaled_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Model\n",
    "Run regression using Lasso Model with alpha=0.1\n",
    "\n",
    "TODO add details on alpha value section MPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  0.1356003604079766\n",
      "MSE  0.033043271455379934\n",
      "R2S  0.40135360420320854\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_scaled_train, y_train)\n",
    "\n",
    "# Determine accuracy using the train set\n",
    "y_hat_train = clf.predict(X_scaled_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE \", mean_absolute_error(y_train, y_hat_train))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE \", mean_squared_error(y_train, y_hat_train))\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2S \", r2_score(y_train, y_hat_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(clf.coef_)\n",
    "#print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(599,)\n",
      "(599,)\n",
      "[0.14497237 0.21159577 0.21617244 0.14703537 0.24271668]\n",
      "[0.06 0.37 0.22 0.01 0.16]\n",
      "0.3895474282936744\n"
     ]
    }
   ],
   "source": [
    "print(y_hat.shape)\n",
    "print(y_test.shape)\n",
    "print(y_hat[0:5])\n",
    "print(y_test[0:5])\n",
    "print(clf.score(X_scaled_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14497237 0.21159577 0.21617244 0.14703537 0.24271668 0.23589178\n",
      " 0.25524453 0.21172655 0.28332429 0.28983775 0.27660609 0.13757445\n",
      " 0.20464995 0.21431874 0.15218048 0.18010368 0.19212354 0.32493797\n",
      " 0.15655073 0.30072435]\n",
      "[0.06 0.37 0.22 0.01 0.16 0.08 0.1 0.1 0.28 0.28 0.46 0.03 0.09 0.22 0.05\n",
      " 0.18 0.02 0.28 0.02 0.4]\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(y_test, y_hat)\n",
    "print(y_hat[0:20])\n",
    "print(y_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  0.13419270424585658\n",
      "MSE  0.03175659751346362\n",
      "R2S  0.3895474282936744\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE \", mean_absolute_error(y_test, y_hat))\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE \", mean_squared_error(y_test, y_hat))\n",
    "#from sklearn.metrics import r2_score\n",
    "print(\"R2S \", r2_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000498969217524633\n",
      "MAE  0.1356003604079766\n",
      "MSE  0.033043271455379934\n",
      "R2S  0.40135360420320854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso_cv = LassoCV(alphas = None, cv = 10, max_iter = 100000, random_state=SEED) \n",
    "lasso_cv.fit(X_scaled_train, y_train)\n",
    "print(lasso_cv.alpha_)\n",
    "#print(lasso_cv.mse_path_)\n",
    "#print(lasso_cv.alphas_)\n",
    "\n",
    "# Determine accuracy using the train set\n",
    "y_hat_cv_train = clf.predict(X_scaled_train)\n",
    "\n",
    "print(\"MAE \", mean_absolute_error(y_train, y_hat_cv_train))\n",
    "print(\"MSE \", mean_squared_error(y_train, y_hat_cv_train))\n",
    "print(\"R2S \", r2_score(y_train, y_hat_cv_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02165816 0.21750937 0.2220265  0.05833631 0.26408214 0.06754418\n",
      " 0.26458617 0.18526805 0.3545354  0.35013111 0.40563335 0.01003609\n",
      " 0.13907604 0.29453351 0.06802299 0.11531183 0.10363523 0.40296194\n",
      " 0.03125358 0.30640838]\n",
      "[0.06 0.37 0.22 0.01 0.16 0.08 0.1 0.1 0.28 0.28 0.46 0.03 0.09 0.22 0.05\n",
      " 0.18 0.02 0.28 0.02 0.4]\n",
      "MAE  0.0935173271739948\n",
      "MSE  0.018936138738425163\n",
      "R2S  0.6359932897043341\n"
     ]
    }
   ],
   "source": [
    "y_hat_cv = lasso_cv.predict(X_scaled_test)\n",
    "print(y_hat_cv[0:20])\n",
    "print(y_test[0:20])\n",
    "print(\"MAE \", mean_absolute_error(y_test, y_hat_cv))\n",
    "print(\"MSE \", mean_squared_error(y_test, y_hat_cv))\n",
    "print(\"R2S \", r2_score(y_test, y_hat_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "pca = PCA()\n",
    "pca.fit(X_scaled_train)\n",
    "X_pca_train = pca.transform(X_scaled_train)\n",
    "print(pca.explained_variance_)\n",
    "print(len(pca.explained_variance_))\n",
    "print(X_pca_train.shape)\n",
    "print(type(pca.explained_variance_))\n",
    "print(pca.explained_variance_.sum())\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "n_components_pca = 0\n",
    "\n",
    "percent_contrib = 0.05\n",
    "\n",
    "for i in range(len(pca.explained_variance_)):\n",
    "    if(pca.explained_variance_ratio_[i]>=(percent_contrib/100)):\n",
    "        n_components_pca+=1\n",
    "print(\"Number of PCA components that contribute >=\",percent_contrib,\"% of variance is \",n_components_pca)\n",
    "\n",
    "pca_red = PCA(n_components=n_components_pca)\n",
    "pca_red.fit(X_scaled_train)\n",
    "X_pca_red_train = pca_red.transform(X_scaled_train)\n",
    "X_pca_red_test = pca_red.transform(X_scaled_test)\n",
    "print(pca_red.explained_variance_)\n",
    "print(len(pca_red.explained_variance_))\n",
    "print(X_pca_red_train.shape)\n",
    "print(X_pca_red_test.shape)\n",
    "print(type(pca_red.explained_variance_))\n",
    "print(pca_red.explained_variance_.sum())\n",
    "print(pca_red.explained_variance_ratio_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_pca = linear_model.Lasso(alpha=0.1)\n",
    "clf_pca.fit(X_pca_red_train, y_train)\n",
    "y_pca_red_hat = clf_pca.predict(X_pca_red_test)\n",
    "print(y_pca_red_hat.shape)\n",
    "print(y_test.shape)\n",
    "print(y_pca_red_hat[0:5])\n",
    "print(y_test[0:5])\n",
    "print(clf_pca.score(X_pca_red_test,y_test))\n",
    "print(\"MAE \", mean_absolute_error(y_test, y_pca_red_hat))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE \", mean_squared_error(y_test, y_pca_red_hat))\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2S \", r2_score(y_test, y_pca_red_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso_pca_cv = LassoCV(alphas = None, cv = 10, max_iter = 1000, random_state=SEED) \n",
    "lasso_pca_cv.fit(X_pca_red_train, y_train)\n",
    "print(lasso_pca_cv.alpha_)\n",
    "\n",
    "y_pca_red_hat_cv = lasso_pca_cv.predict(X_pca_red_test)\n",
    "print(y_pca_red_hat_cv[0:20])\n",
    "print(y_test[0:20])\n",
    "print(\"MAE \", mean_absolute_error(y_test, y_pca_red_hat_cv))\n",
    "print(\"MSE \", mean_squared_error(y_test, y_pca_red_hat_cv))\n",
    "print(\"R2S \", r2_score(y_test, y_pca_red_hat_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Finally we will visualize the results by comparing predictive power of n_components classifier, original_classifier and the classifier after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_for_count_of_components = PCA()\n",
    "pca_for_count_of_components.fit(X_scaled_train)\n",
    "total_components = len(pca.explained_variance_)\n",
    "pca_results_n_components_lasso = []\n",
    "pca_results_n_components_lasso_cv = []\n",
    "\n",
    "for i in range(total_components):\n",
    "    pca_n = PCA(n_components=i+1)\n",
    "    pca_n.fit(X_scaled_train)\n",
    "    X_pca_n_train = pca_n.transform(X_scaled_train)\n",
    "    X_pca_n_test = pca_n.transform(X_scaled_test)\n",
    "    clf_pca = linear_model.Lasso(alpha=0.1)\n",
    "    clf_pca.fit(X_pca_n_train, y_train)\n",
    "    y_n_hat = clf_pca.predict(X_pca_n_test)\n",
    "    mae = mean_absolute_error(y_test, y_n_hat)\n",
    "    mse = mean_squared_error(y_test, y_n_hat)\n",
    "    r2s = r2_score(y_test, y_n_hat)\n",
    "    pca_results_n_components_lasso.append((mae,mse,r2s))\n",
    "    \n",
    "    lasso_pca_cv_n = LassoCV(alphas = None, cv = 10, max_iter = 1000, random_state=SEED) \n",
    "    lasso_pca_cv_n.fit(X_pca_n_train, y_train)\n",
    "    y_n_hat_cv = lasso_pca_cv_n.predict(X_pca_n_test)\n",
    "    mae_cv = mean_absolute_error(y_test, y_n_hat_cv)\n",
    "    mse_cv = mean_squared_error(y_test, y_n_hat_cv)\n",
    "    r2s_cv = r2_score(y_test, y_n_hat_cv)\n",
    "    pca_results_n_components_lasso_cv.append((mae_cv,mse_cv,r2s_cv))\n",
    "    \n",
    "    \n",
    "maes, mses, r2ss = zip(*pca_results_n_components_lasso)\n",
    "maes_cv, mses_cv, r2ss_cv = zip(*pca_results_n_components_lasso_cv)\n",
    "\n",
    "from matplotlib.pylab import plt #load plot library\n",
    "# indicate the output of plotting function is printed to the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "mae_original =  mean_absolute_error(y_test, y_hat)\n",
    "mse_original =  mean_squared_error(y_test, y_hat)\n",
    "r2s_original = r2_score(y_test, y_hat)\n",
    "\n",
    "mae_cv =  mean_absolute_error(y_test, y_hat_cv)\n",
    "mse_cv =  mean_squared_error(y_test, y_hat_cv)\n",
    "r2s_cv = r2_score(y_test, y_hat_cv)\n",
    "\n",
    "plt.title(\"absolute errors\")\n",
    "plt.xlabel(\"n_components\")\n",
    "plt.axhline(y=mae_original, color='r', linestyle='-', label=\"original regression\")\n",
    "plt.axhline(y=mae_cv, color='g', linestyle='-.', label=\"regression after grid search\")\n",
    "plt.plot(maes, color='b', label=\"lasso regression after PCA\")\n",
    "plt.plot(maes_cv, color='y', label=\"lasso regression after PCA and grid search\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"original_regression: {}\".format(mae_original))\n",
    "print(\"regression after grid search: {}\".format(mae_cv))\n",
    "print(\"regression after PCA: {}\".format(maes[-1]))\n",
    "print(\"regression after PCA and grid search: {}\".format(maes_cv[-1]))\n",
    "\n",
    "plt.title(\"mean square error\")\n",
    "plt.xlabel(\"n_components\")\n",
    "plt.axhline(y=mse_original, color='r', linestyle='-', label=\"original regression\")\n",
    "plt.axhline(y=mse_cv, color='g', linestyle='-.', label=\"regression after grid search\")\n",
    "plt.plot(mses, color='b', label=\"lasso regression after PCA\")\n",
    "plt.plot(mses_cv, color='y', label=\"lasso regression after PCA and grid search\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"original_regression: {}\".format(mse_original))\n",
    "print(\"regression after grid search: {}\".format(mse_cv))\n",
    "print(\"regression after PCA: {}\".format(mses[-1]))\n",
    "print(\"regression after PCA and grid search: {}\".format(mses_cv[-1]))\n",
    "\n",
    "plt.title(\"r2 scores\")\n",
    "plt.xlabel(\"n_components\")\n",
    "plt.axhline(y=r2s_original, color='r', linestyle='-', label=\"original regression\")\n",
    "plt.axhline(y=r2s_cv, color='g', linestyle='-.', label=\"regression after grid search\")\n",
    "plt.plot(r2ss, color='b', label=\"lasso regression after PCA\")\n",
    "plt.plot(r2ss_cv, color='y', label=\"lasso regression after PCA and grid search\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"original_regression: {}\".format(r2s_original))\n",
    "print(\"regression after grid search: {}\".format(r2s_cv))\n",
    "print(\"regression after PCA: {}\".format(r2ss[-1]))\n",
    "print(\"regression after PCA and grid search: {}\".format(r2ss_cv[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "* [1] [Depy 2016 Talk: Pre-Modeling: Data Preprocessing and Feature Exploration in Python Notebook](https://github.com/aprilypchen/depy2016/blob/master/DePy_Talk.ipynb)\n",
    "* [2] [amclean3695's Communities-and-Crime Notebook](https://github.com/amclean3695/Communities-and-Crime/blob/master/Communities_and_Crime.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
