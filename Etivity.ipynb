{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Student Name:\n",
    "#Student ID:\n",
    "\n",
    "#Student Name:\n",
    "#Student ID:\n",
    "\n",
    "#Student Name:\n",
    "#Student ID:\n",
    "\n",
    "#Student Name:\n",
    "#Student ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Following code is from https://github.com/amclean3695/Communities-and-Crime/blob/master/Communities_and_Crime.ipynb\n",
    "# TODO : See is there any other means for pulling column names from C45 file format\n",
    "#Reads in names from textfile and performs regex to extract the attribute names \n",
    "textfile = open('communities.names','r')\n",
    "filetext = textfile.read()\n",
    "textfile.close()\n",
    "matches = re.findall(r'-{2}\\s(\\w+)\\:{1}', filetext)\n",
    "col_names = matches[2:] #corresponds to the 128 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 128)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('communities.data', header=None, names=col_names)\n",
    "\n",
    "#data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data'\n",
    "#df = pd.read_csv(data_url, header=None)\n",
    "# The above code does not work as PythonAnywhere blocks outgoing connections for free accounts to non-whitelisted sites\n",
    "\n",
    "#print(df.head(5))\n",
    "#dir(df)\n",
    "print(df.shape)\n",
    "#print(df['ViolentCrimesPerPop'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Non-Predictive Attributes\n",
    "\n",
    "Of the 128 attributes loaded, for this dataset it is stated that:\n",
    "\n",
    "Attribute Information: (122 predictive, 5 non-predictive, 1 goal) \n",
    "* state: US state (by number) - not counted as predictive above, but if considered, should be consided nominal (nominal) \n",
    "* county: numeric code for county - not predictive, and many missing values (numeric) \n",
    "* community: numeric code for community - not predictive and many missing values (numeric) \n",
    "* communityname: community name - not predictive - for information only (string) \n",
    "* fold: fold number for non-random 10 fold cross validation, potentially useful for debugging, paired tests - not predictive (numeric) \n",
    "\n",
    "Therefore, the first five columns shall be removed from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 123)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['state', 'county', 'community', 'communityname', 'fold'], axis=1)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViolentCrimesPerPop    0\n",
       "PctNotHSGrad           0\n",
       "PctUnemployed          0\n",
       "PctEmploy              0\n",
       "PctEmplManu            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df.head(5))\n",
    "# From DePy_Talk Noteboook\n",
    "# How much of your data is missing?\n",
    "df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no cells with missing data\n",
    "However, visually inspecting the data, there are cells with \"?\" and this needs to be replaced with \"NaN\" (Not a Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OtherPerCap', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps',\n",
      "       'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop',\n",
      "       'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol',\n",
      "       'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian',\n",
      "       'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz',\n",
      "       'PolicAveOTWorked', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr',\n",
      "       'LemasGangUnitDeploy', 'PolicBudgPerPop'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.replace('?', np.nan)\n",
    "print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LemasSwFTFieldPerPop    1675\n",
       "PctPolicAsian           1675\n",
       "PolicBudgPerPop         1675\n",
       "LemasSwornFT            1675\n",
       "LemasSwFTPerPop         1675\n",
       "LemasSwFTFieldOps       1675\n",
       "LemasTotalReq           1675\n",
       "LemasTotReqPerPop       1675\n",
       "PolicReqPerOffic        1675\n",
       "PolicPerPop             1675\n",
       "RacialMatchCommPol      1675\n",
       "PctPolicBlack           1675\n",
       "PctPolicHisp            1675\n",
       "PctPolicWhite           1675\n",
       "PctPolicMinor           1675\n",
       "PolicCars               1675\n",
       "LemasGangUnitDeploy     1675\n",
       "LemasPctPolicOnPatr     1675\n",
       "OfficAssgnDrugUnits     1675\n",
       "PolicOperBudg           1675\n",
       "PolicAveOTWorked        1675\n",
       "NumKindsDrugsSeiz       1675\n",
       "OtherPerCap                1\n",
       "PctLess9thGrade            0\n",
       "PctPopUnderPov             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 123)\n",
      "1994\n",
      "1675\n",
      "Column  LemasSwornFT 1675\n",
      "Column  LemasSwFTPerPop 1675\n",
      "Column  LemasSwFTFieldOps 1675\n",
      "Column  LemasSwFTFieldPerPop 1675\n",
      "Column  LemasTotalReq 1675\n",
      "Column  LemasTotReqPerPop 1675\n",
      "Column  PolicReqPerOffic 1675\n",
      "Column  PolicPerPop 1675\n",
      "Column  RacialMatchCommPol 1675\n",
      "Column  PctPolicWhite 1675\n",
      "Column  PctPolicBlack 1675\n",
      "Column  PctPolicHisp 1675\n",
      "Column  PctPolicAsian 1675\n",
      "Column  PctPolicMinor 1675\n",
      "Column  OfficAssgnDrugUnits 1675\n",
      "Column  NumKindsDrugsSeiz 1675\n",
      "Column  PolicAveOTWorked 1675\n",
      "Column  PolicCars 1675\n",
      "Column  PolicOperBudg 1675\n",
      "Column  LemasPctPolicOnPatr 1675\n",
      "Column  LemasGangUnitDeploy 1675\n",
      "Column  PolicBudgPerPop 1675\n",
      "(1994, 101)\n"
     ]
    }
   ],
   "source": [
    "#print(df.isnull().sum())\n",
    "print(df.shape)\n",
    "print(df.shape[0])\n",
    "print(df['LemasSwFTFieldPerPop'].isnull().sum())\n",
    "for column in df:\n",
    "    if(df[column].isnull().sum()>=(df.shape[0]/2)):\n",
    "        print(\"Column \", column, df[column].isnull().sum())\n",
    "        df = df.drop([column], axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OtherPerCap            1\n",
       "PctOccupManu           0\n",
       "HispPerCap             0\n",
       "NumUnderPov            0\n",
       "PctPopUnderPov         0\n",
       "PctLess9thGrade        0\n",
       "PctNotHSGrad           0\n",
       "PctBSorMore            0\n",
       "PctUnemployed          0\n",
       "PctEmploy              0\n",
       "PctEmplManu            0\n",
       "PctEmplProfServ        0\n",
       "ViolentCrimesPerPop    0\n",
       "NumIlleg               0\n",
       "MalePctDivorce         0\n",
       "MalePctNevMarr         0\n",
       "FemalePctDiv           0\n",
       "TotalPctDiv            0\n",
       "PersPerFam             0\n",
       "PctFam2Par             0\n",
       "PctKids2Par            0\n",
       "PctYoungKids2Par       0\n",
       "PctTeen2Par            0\n",
       "PctWorkMomYoungKids    0\n",
       "PctOccupMgmtProf       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one missing value remaining but lets impute it for the craic using code from the DePy_Talk notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/IPython/kernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# print(df['OtherPerCap'][130])\n",
    "\n",
    "# # dir(sklearn)\n",
    "# # from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# # imp.fit(df) \n",
    "# # X = pd.DataFrame(data=imp.transform(df) , columns=df.columns)\n",
    "\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# my_imputer = SimpleImputer()\n",
    "\n",
    "#TEMP WORKAROUND\n",
    "# Set to median\n",
    "print(df['OtherPerCap'][130])\n",
    "#print(df['OtherPerCap'].median())\n",
    "#print(df['OtherPerCap'].mean())\n",
    "dir(df['OtherPerCap'])\n",
    "miss_median = df['OtherPerCap'].median()\n",
    "df['OtherPerCap'][130] = miss_median\n",
    "print(df['OtherPerCap'][130])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Before Outlier Removal\n",
      "(1994, 101)\n",
      "Entry 26 0.84\n",
      "Outliers =  110 out of  1994\n",
      "[0.73 0.73 0.73 0.74 0.74 0.74 0.75 0.75 0.75 0.75 0.75 0.76 0.76 0.76\n",
      " 0.76 0.77 0.78 0.78 0.79 0.79 0.8  0.8  0.8  0.81 0.81 0.81 0.81 0.81\n",
      " 0.82 0.82 0.82 0.82 0.83 0.83 0.83 0.83 0.84 0.84 0.85 0.85 0.85 0.86\n",
      " 0.86 0.86 0.86 0.86 0.87 0.87 0.87 0.87 0.88 0.88 0.89 0.9  0.9  0.9\n",
      " 0.91 0.91 0.93 0.93 0.94 0.95 0.95 0.96 0.97 0.97 1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.  ]\n",
      "[  26   42   79   82  116  146  149  151  154  157  174  177  226  233\n",
      "  248  250  255  333  362  375  399  400  410  413  420  427  447  457\n",
      "  462  472  499  539  545  560  564  591  600  615  630  631  641  667\n",
      "  669  675  676  678  723  726  776  810  828  836  841  858  866  867\n",
      "  909  952  953  955  957  976  998 1001 1025 1041 1044 1056 1119 1134\n",
      " 1154 1159 1200 1208 1211 1262 1270 1273 1274 1292 1295 1326 1353 1364\n",
      " 1392 1486 1502 1524 1544 1554 1563 1595 1610 1612 1633 1636 1640 1663\n",
      " 1684 1721 1759 1773 1775 1831 1836 1847 1865 1878 1957 1969]\n",
      "i :  0 Index 26 Value 0.84\n",
      "i :  1 Index 42 Value 0.8\n",
      "i :  2 Index 79 Value 0.75\n",
      "i :  3 Index 82 Value 1.0\n",
      "i :  4 Index 116 Value 0.86\n",
      "i :  5 Index 146 Value 1.0\n",
      "i :  6 Index 149 Value 1.0\n",
      "i :  7 Index 151 Value 0.86\n",
      "i :  8 Index 154 Value 0.87\n",
      "i :  9 Index 157 Value 0.73\n",
      "i :  10 Index 174 Value 0.73\n",
      "i :  11 Index 177 Value 0.83\n",
      "i :  12 Index 226 Value 0.74\n",
      "i :  13 Index 233 Value 0.88\n",
      "i :  14 Index 248 Value 1.0\n",
      "i :  15 Index 250 Value 0.74\n",
      "i :  16 Index 255 Value 0.93\n",
      "i :  17 Index 333 Value 1.0\n",
      "i :  18 Index 362 Value 1.0\n",
      "i :  19 Index 375 Value 0.83\n",
      "i :  20 Index 399 Value 0.8\n",
      "i :  21 Index 400 Value 1.0\n",
      "i :  22 Index 410 Value 1.0\n",
      "i :  23 Index 413 Value 1.0\n",
      "i :  24 Index 420 Value 1.0\n",
      "i :  25 Index 427 Value 0.76\n",
      "i :  26 Index 447 Value 1.0\n",
      "i :  27 Index 457 Value 1.0\n",
      "i :  28 Index 462 Value 1.0\n",
      "i :  29 Index 472 Value 0.78\n",
      "i :  30 Index 499 Value 1.0\n",
      "i :  31 Index 539 Value 0.91\n",
      "i :  32 Index 545 Value 0.86\n",
      "i :  33 Index 560 Value 0.85\n",
      "i :  34 Index 564 Value 1.0\n",
      "i :  35 Index 591 Value 0.87\n",
      "i :  36 Index 600 Value 0.87\n",
      "i :  37 Index 615 Value 0.82\n",
      "i :  38 Index 630 Value 0.89\n",
      "i :  39 Index 631 Value 0.85\n",
      "i :  40 Index 641 Value 0.94\n",
      "i :  41 Index 667 Value 1.0\n",
      "i :  42 Index 669 Value 0.81\n",
      "i :  43 Index 675 Value 0.95\n",
      "i :  44 Index 676 Value 0.81\n",
      "i :  45 Index 678 Value 1.0\n",
      "i :  46 Index 723 Value 0.82\n",
      "i :  47 Index 726 Value 0.9\n",
      "i :  48 Index 776 Value 1.0\n",
      "i :  49 Index 810 Value 1.0\n",
      "i :  50 Index 828 Value 1.0\n",
      "i :  51 Index 836 Value 0.79\n",
      "i :  52 Index 841 Value 1.0\n",
      "i :  53 Index 858 Value 0.97\n",
      "i :  54 Index 866 Value 0.85\n",
      "i :  55 Index 867 Value 0.76\n",
      "i :  56 Index 909 Value 1.0\n",
      "i :  57 Index 952 Value 0.74\n",
      "i :  58 Index 953 Value 0.73\n",
      "i :  59 Index 955 Value 1.0\n",
      "i :  60 Index 957 Value 1.0\n",
      "i :  61 Index 976 Value 0.77\n",
      "i :  62 Index 998 Value 1.0\n",
      "i :  63 Index 1001 Value 1.0\n",
      "i :  64 Index 1025 Value 1.0\n",
      "i :  65 Index 1041 Value 1.0\n",
      "i :  66 Index 1044 Value 1.0\n",
      "i :  67 Index 1056 Value 1.0\n",
      "i :  68 Index 1119 Value 1.0\n",
      "i :  69 Index 1134 Value 1.0\n",
      "i :  70 Index 1154 Value 1.0\n",
      "i :  71 Index 1159 Value 1.0\n",
      "i :  72 Index 1200 Value 0.82\n",
      "i :  73 Index 1208 Value 1.0\n",
      "i :  74 Index 1211 Value 0.76\n",
      "i :  75 Index 1262 Value 0.84\n",
      "i :  76 Index 1270 Value 0.97\n",
      "i :  77 Index 1273 Value 1.0\n",
      "i :  78 Index 1274 Value 0.96\n",
      "i :  79 Index 1292 Value 0.9\n",
      "i :  80 Index 1295 Value 1.0\n",
      "i :  81 Index 1326 Value 0.83\n",
      "i :  82 Index 1353 Value 0.82\n",
      "i :  83 Index 1364 Value 1.0\n",
      "i :  84 Index 1392 Value 0.86\n",
      "i :  85 Index 1486 Value 0.81\n",
      "i :  86 Index 1502 Value 0.76\n",
      "i :  87 Index 1524 Value 0.93\n",
      "i :  88 Index 1544 Value 0.75\n",
      "i :  89 Index 1554 Value 0.78\n",
      "i :  90 Index 1563 Value 1.0\n",
      "i :  91 Index 1595 Value 0.87\n",
      "i :  92 Index 1610 Value 0.91\n",
      "i :  93 Index 1612 Value 0.81\n",
      "i :  94 Index 1633 Value 0.8\n",
      "i :  95 Index 1636 Value 0.9\n",
      "i :  96 Index 1640 Value 0.79\n",
      "i :  97 Index 1663 Value 0.75\n",
      "i :  98 Index 1684 Value 1.0\n",
      "i :  99 Index 1721 Value 1.0\n",
      "i :  100 Index 1759 Value 1.0\n",
      "i :  101 Index 1773 Value 0.75\n",
      "i :  102 Index 1775 Value 0.83\n",
      "i :  103 Index 1831 Value 0.81\n",
      "i :  104 Index 1836 Value 0.86\n",
      "i :  105 Index 1847 Value 1.0\n",
      "i :  106 Index 1865 Value 0.95\n",
      "i :  107 Index 1878 Value 0.88\n",
      "i :  108 Index 1957 Value 1.0\n",
      "i :  109 Index 1969 Value 0.75\n",
      "Shape After Outlier Removal\n",
      "(1884, 101)\n"
     ]
    }
   ],
   "source": [
    "# From DePy_Talk Notebook\n",
    "# def find_outliers_tukey(x):\n",
    "#     q1 = np.percentile(x, 25)\n",
    "#     q3 = np.percentile(x, 75)\n",
    "#     iqr = q3-q1\n",
    "#     floor = q1 - 1.5*iqr\n",
    "#     ceiling = q3 + 1.5*iqr\n",
    "#     outlier_indices = list(x.index[(x < floor)|(x > ceiling)])\n",
    "#     outlier_values = list(x[outlier_indices])\n",
    "    \n",
    "#     return outlier_indices, outlier_values\n",
    "\n",
    "# tukey_indices, tukey_values = find_outliers_tukey(df['ViolentCrimesPerPop'])\n",
    "\n",
    "# print(\"Shape Before Outlier Removal\")\n",
    "# print(df.shape)\n",
    "# print(\"Entry 26\", df['ViolentCrimesPerPop'][26])\n",
    "# print(\"Outliers = \",len(tukey_indices), \"out of \",len(df['ViolentCrimesPerPop']))\n",
    "# print(np.sort(tukey_values))\n",
    "# print(np.sort(tukey_indices))\n",
    "# for i in range(len(tukey_indices)):\n",
    "#     print(\"i : \", i, \"Index\", tukey_indices[i], \"Value\", tukey_values[i])\n",
    "#     # Drop row containing the outlier\n",
    "#     df = df.drop([tukey_indices[i]], axis=0)\n",
    "# print(\"Shape After Outlier Removal\")\n",
    "# print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.20\n",
      "1       0.67\n",
      "2       0.43\n",
      "3       0.12\n",
      "4       0.03\n",
      "5       0.14\n",
      "6       0.03\n",
      "7       0.55\n",
      "8       0.53\n",
      "9       0.15\n",
      "10      0.24\n",
      "11      0.08\n",
      "12      0.06\n",
      "13      0.09\n",
      "14      0.21\n",
      "15      0.30\n",
      "16      0.49\n",
      "17      0.07\n",
      "18      0.15\n",
      "19      0.03\n",
      "20      0.34\n",
      "21      0.69\n",
      "22      0.21\n",
      "23      0.63\n",
      "24      0.31\n",
      "25      0.12\n",
      "27      0.10\n",
      "28      0.49\n",
      "29      0.02\n",
      "30      0.16\n",
      "        ... \n",
      "1963    0.45\n",
      "1964    0.60\n",
      "1965    0.69\n",
      "1966    0.30\n",
      "1967    0.04\n",
      "1968    0.19\n",
      "1970    0.53\n",
      "1971    0.22\n",
      "1972    0.30\n",
      "1973    0.04\n",
      "1974    0.52\n",
      "1975    0.09\n",
      "1976    0.08\n",
      "1977    0.25\n",
      "1978    0.04\n",
      "1979    0.16\n",
      "1980    0.28\n",
      "1981    0.07\n",
      "1982    0.03\n",
      "1983    0.56\n",
      "1984    0.14\n",
      "1985    0.14\n",
      "1986    0.02\n",
      "1987    0.04\n",
      "1988    0.19\n",
      "1989    0.09\n",
      "1990    0.45\n",
      "1991    0.23\n",
      "1992    0.19\n",
      "1993    0.48\n",
      "Name: ViolentCrimesPerPop, Length: 1884, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['ViolentCrimesPerPop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split Up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1884, 101)\n",
      "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
      "0        0.19           0.33          0.02          0.90          0.12   \n",
      "1        0.00           0.16          0.12          0.74          0.45   \n",
      "2        0.00           0.42          0.49          0.56          0.17   \n",
      "3        0.04           0.77          1.00          0.08          0.12   \n",
      "4        0.01           0.55          0.02          0.95          0.09   \n",
      "\n",
      "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
      "0         0.17         0.34         0.47         0.29        0.32   \n",
      "1         0.07         0.26         0.59         0.35        0.27   \n",
      "2         0.04         0.39         0.47         0.28        0.32   \n",
      "3         0.10         0.51         0.50         0.34        0.21   \n",
      "4         0.05         0.38         0.38         0.23        0.36   \n",
      "\n",
      "          ...           PctForeignBorn  PctBornSameState  PctSameHouse85  \\\n",
      "0         ...                     0.12              0.42            0.50   \n",
      "1         ...                     0.21              0.50            0.34   \n",
      "2         ...                     0.14              0.49            0.54   \n",
      "3         ...                     0.19              0.30            0.73   \n",
      "4         ...                     0.11              0.72            0.64   \n",
      "\n",
      "   PctSameCity85  PctSameState85  LandArea  PopDens  PctUsePubTrans  \\\n",
      "0           0.51            0.64      0.12     0.26            0.20   \n",
      "1           0.60            0.52      0.02     0.12            0.45   \n",
      "2           0.67            0.56      0.01     0.21            0.02   \n",
      "3           0.64            0.65      0.02     0.39            0.28   \n",
      "4           0.61            0.53      0.04     0.09            0.02   \n",
      "\n",
      "   LemasPctOfficDrugUn  ViolentCrimesPerPop  \n",
      "0                 0.32                 0.20  \n",
      "1                 0.00                 0.67  \n",
      "2                 0.00                 0.43  \n",
      "3                 0.00                 0.12  \n",
      "4                 0.00                 0.03  \n",
      "\n",
      "[5 rows x 101 columns]\n",
      "(1884, 101)\n",
      "[0.19 0.33 0.02 0.9 0.12 0.17 0.34 0.47 0.29 0.32 0.2 1.0 0.37 0.72 0.34\n",
      " 0.6 0.29 0.15 0.43 0.39 0.4 0.39 0.32 0.27 0.27 '0.36' 0.41 0.08 0.19 0.1\n",
      " 0.18 0.48 0.27 0.68 0.23 0.41 0.25 0.52 0.68 0.4 0.75 0.75 0.35 0.55 0.59\n",
      " 0.61 0.56 0.74 0.76 0.04 0.14 0.03 0.24 0.27 0.37 0.39 0.07 0.07 0.08\n",
      " 0.08 0.89 0.06 0.14 0.13 0.33 0.39 0.28 0.55 0.09 0.51 0.5 0.21 0.71 0.52\n",
      " 0.05 0.26 0.65 0.14 0.06 0.22 0.19 0.18 0.36 0.35 0.38 0.34 0.38 0.46\n",
      " 0.25 0.04 0.0 0.12 0.42 0.5 0.51 0.64 0.12 0.26 0.2 0.32]\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())\n",
    "dataset = df.values\n",
    "print(dataset.shape)\n",
    "X = dataset[:, 0:100]\n",
    "y = dataset[:, 100]\n",
    "print(X[0])\n",
    "#X = df[:,0:100].values\n",
    "#y = df[:,100].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ul9939245/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ul9939245/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ul9939245/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Scale the dataset\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# Scale the data with respect to the training data set \n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train) \n",
    "\n",
    "X_scaled_train = scaler.transform(X_train) \n",
    "# Scaling the test set using the transform defined by the train set. \n",
    "X_scaled_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1507, 100)\n",
      "(377, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled_train.shape)\n",
    "print(X_scaled_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         -0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.         -0.         -0.         -0.          0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.          0.          0.          0.\n",
      "  0.         -0.          0.         -0.         -0.         -0.\n",
      "  0.         -0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.02035968 -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.         -0.\n",
      "  0.         -0.          0.          0.         -0.          0.\n",
      " -0.         -0.          0.         -0.         -0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.         -0.          0.\n",
      "  0.          0.         -0.         -0.          0.         -0.\n",
      "  0.          0.          0.          0.        ]\n",
      "0.1983676177836763\n"
     ]
    }
   ],
   "source": [
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(377,)\n",
      "(377,)\n",
      "[0.16555333 0.20292006 0.20292006 0.16875619 0.20185244]\n",
      "[0.05 0.28 0.16 0.04 0.24]\n",
      "0.14076042961651192\n"
     ]
    }
   ],
   "source": [
    "print(y_hat.shape)\n",
    "print(y_test.shape)\n",
    "print(y_hat[0:5])\n",
    "print(y_test[0:5])\n",
    "print(clf.score(X_scaled_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16555333 0.20292006 0.20292006 0.16875619 0.20185244 0.20825817\n",
      " 0.21146103 0.22747534 0.17836478 0.19224385 0.18050002 0.19437909\n",
      " 0.19651434 0.1794324  0.18583813 0.19010861 0.19437909 0.22427248\n",
      " 0.18583813 0.21146103]\n",
      "[0.05 0.28 0.16 0.04 0.24 0.21 0.4 0.36 0.04 0.03 0.14 0.19 0.16 0.13 0.18\n",
      " 0.36 0.05 0.52 0.02 0.09]\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(y_test, y_hat)\n",
    "print(y_hat[0:20])\n",
    "print(y_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  0.12368584519753385\n",
      "MSE  0.02429427052208181\n",
      "R2S  0.14076042961651192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE \", mean_absolute_error(y_test, y_hat))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE \", mean_squared_error(y_test, y_hat))\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2S \", r2_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001483850379105968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso_cv = LassoCV(alphas = None, cv = 10, max_iter = 100000, random_state=1) \n",
    "lasso_cv.fit(X_scaled_train, y_train)\n",
    "print(lasso_cv.alpha_)\n",
    "#print(lasso_cv.mse_path_)\n",
    "#print(lasso_cv.alphas_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00344722  0.18839076  0.26879589  0.01994383  0.13933228  0.26733997\n",
      "  0.40733025  0.32498373  0.09279517  0.11048849  0.07885754  0.15683005\n",
      "  0.16033197  0.0534839   0.11631749  0.19311162  0.1884257   0.33834337\n",
      "  0.0445184   0.20456927]\n",
      "[0.05 0.28 0.16 0.04 0.24 0.21 0.4 0.36 0.04 0.03 0.14 0.19 0.16 0.13 0.18\n",
      " 0.36 0.05 0.52 0.02 0.09]\n",
      "MAE  0.08354865135259368\n",
      "MSE  0.012934545858282779\n",
      "R2S  0.542531082945064\n"
     ]
    }
   ],
   "source": [
    "y_hat_cv = lasso_cv.predict(X_scaled_test)\n",
    "print(y_hat_cv[0:20])\n",
    "print(y_test[0:20])\n",
    "print(\"MAE \", mean_absolute_error(y_test, y_hat_cv))\n",
    "print(\"MSE \", mean_squared_error(y_test, y_hat_cv))\n",
    "print(\"R2S \", r2_score(y_test, y_hat_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.53389904e+01 1.60551651e+01 9.24224043e+00 7.30850845e+00\n",
      " 5.86393001e+00 4.22326901e+00 3.21383004e+00 2.89620146e+00\n",
      " 2.12491830e+00 1.66292526e+00 1.55366828e+00 1.48991928e+00\n",
      " 1.37254275e+00 1.04538337e+00 9.27806043e-01 8.83034793e-01\n",
      " 8.18951642e-01 7.84032396e-01 7.19236995e-01 6.66352892e-01\n",
      " 6.46130918e-01 6.25133887e-01 5.93365637e-01 5.43366469e-01\n",
      " 5.21728839e-01 4.88606794e-01 4.61405244e-01 4.43865970e-01\n",
      " 4.05327549e-01 3.94410166e-01 3.74987215e-01 3.68567782e-01\n",
      " 3.53505050e-01 3.36881432e-01 3.07633097e-01 2.88994698e-01\n",
      " 2.80964444e-01 2.72948857e-01 2.55307389e-01 2.42632742e-01\n",
      " 2.30318112e-01 2.16740752e-01 2.10053349e-01 2.01961694e-01\n",
      " 1.91819191e-01 1.81033854e-01 1.64798877e-01 1.48340854e-01\n",
      " 1.45273163e-01 1.33252917e-01 1.19058471e-01 1.12044374e-01\n",
      " 1.09630631e-01 1.03594007e-01 9.75739528e-02 8.48152087e-02\n",
      " 7.73580547e-02 7.68028576e-02 7.23928938e-02 6.83373205e-02\n",
      " 6.67382818e-02 6.23017993e-02 5.92601904e-02 5.43128252e-02\n",
      " 4.90009179e-02 4.65001799e-02 4.48222096e-02 4.24042148e-02\n",
      " 4.04412995e-02 3.86217000e-02 3.49163580e-02 3.45511552e-02\n",
      " 3.18574454e-02 3.10541128e-02 2.78895479e-02 2.65489181e-02\n",
      " 2.54180199e-02 2.19702388e-02 2.14674878e-02 2.07221636e-02\n",
      " 1.92637196e-02 1.66522100e-02 1.59389640e-02 1.41641806e-02\n",
      " 1.26762666e-02 1.20587420e-02 9.48818492e-03 8.59064488e-03\n",
      " 5.90452888e-03 5.74333648e-03 5.04293671e-03 3.96463579e-03\n",
      " 3.02511900e-03 2.93503630e-03 2.31692358e-03 2.01759275e-03\n",
      " 1.40839992e-03 1.08520125e-03 7.56376599e-04 6.97473493e-04]\n",
      "100\n",
      "(1507, 100)\n",
      "<class 'numpy.ndarray'>\n",
      "100.066401062417\n",
      "[2.53221762e-01 1.60445113e-01 9.23610755e-02 7.30365874e-02\n",
      " 5.86003888e-02 4.22046657e-02 3.21169744e-02 2.89427963e-02\n",
      " 2.12350826e-02 1.66182179e-02 1.55263731e-02 1.48893062e-02\n",
      " 1.37163197e-02 1.04468968e-02 9.27190379e-03 8.82448837e-03\n",
      " 8.18408210e-03 7.83512135e-03 7.18759731e-03 6.65910721e-03\n",
      " 6.45702165e-03 6.24719067e-03 5.92971897e-03 5.43005908e-03\n",
      " 5.21382635e-03 4.88282569e-03 4.61099070e-03 4.43571434e-03\n",
      " 4.05058586e-03 3.94148447e-03 3.74738384e-03 3.68323211e-03\n",
      " 3.53270475e-03 3.36657888e-03 3.07428961e-03 2.88802930e-03\n",
      " 2.80778004e-03 2.72767736e-03 2.55137975e-03 2.42471738e-03\n",
      " 2.30165280e-03 2.16596929e-03 2.09913964e-03 2.01827678e-03\n",
      " 1.91691906e-03 1.80913725e-03 1.64689522e-03 1.48242420e-03\n",
      " 1.45176764e-03 1.33164495e-03 1.18979467e-03 1.11970025e-03\n",
      " 1.09557883e-03 1.03525265e-03 9.75092057e-04 8.47589278e-04\n",
      " 7.73067222e-04 7.67518935e-04 7.23448561e-04 6.82919739e-04\n",
      " 6.66939963e-04 6.22604577e-04 5.92208671e-04 5.42767848e-04\n",
      " 4.89684024e-04 4.64693238e-04 4.47924669e-04 4.23760766e-04\n",
      " 4.04144638e-04 3.85960718e-04 3.48931886e-04 3.45282281e-04\n",
      " 3.18363057e-04 3.10335062e-04 2.78710412e-04 2.65313010e-04\n",
      " 2.54011533e-04 2.19556600e-04 2.14532426e-04 2.07084130e-04\n",
      " 1.92509367e-04 1.66411601e-04 1.59283874e-04 1.41547817e-04\n",
      " 1.26678551e-04 1.20507402e-04 9.48188884e-05 8.58494438e-05\n",
      " 5.90061081e-05 5.73952537e-05 5.03959036e-05 3.96200498e-05\n",
      " 3.02311163e-05 2.93308870e-05 2.31538613e-05 2.01625393e-05\n",
      " 1.40746534e-05 1.08448114e-05 7.55874690e-06 6.97010670e-06]\n",
      "Number of PCA components that contribute >= 0.05 % of variance is  64\n",
      "[25.33899038 16.05516505  9.24224043  7.30850845  5.86393001  4.22326901\n",
      "  3.21383004  2.89620146  2.1249183   1.66292526  1.55366828  1.48991928\n",
      "  1.37254275  1.04538337  0.92780604  0.88303479  0.81895164  0.7840324\n",
      "  0.719237    0.66635289  0.64613092  0.62513389  0.59336564  0.54336647\n",
      "  0.52172884  0.48860679  0.46140524  0.44386597  0.40532755  0.39441017\n",
      "  0.37498721  0.36856778  0.35350505  0.33688143  0.3076331   0.2889947\n",
      "  0.28096444  0.27294886  0.25530739  0.24263274  0.23031811  0.21674075\n",
      "  0.21005335  0.20196169  0.19181919  0.18103385  0.16479887  0.14834084\n",
      "  0.14527314  0.13325285  0.11905845  0.11204374  0.10963057  0.10359394\n",
      "  0.09757375  0.08481492  0.07735539  0.07678463  0.07239152  0.06831906\n",
      "  0.06672879  0.06227141  0.05924683  0.05424784]\n",
      "64\n",
      "(1507, 64)\n",
      "(377, 64)\n",
      "<class 'numpy.ndarray'>\n",
      "99.38432445789542\n",
      "[0.25322176 0.16044511 0.09236108 0.07303659 0.05860039 0.04220467\n",
      " 0.03211697 0.0289428  0.02123508 0.01661822 0.01552637 0.01488931\n",
      " 0.01371632 0.0104469  0.0092719  0.00882449 0.00818408 0.00783512\n",
      " 0.0071876  0.00665911 0.00645702 0.00624719 0.00592972 0.00543006\n",
      " 0.00521383 0.00488283 0.00461099 0.00443571 0.00405059 0.00394148\n",
      " 0.00374738 0.00368323 0.0035327  0.00336658 0.00307429 0.00288803\n",
      " 0.00280778 0.00272768 0.00255138 0.00242472 0.00230165 0.00216597\n",
      " 0.00209914 0.00201828 0.00191692 0.00180914 0.0016469  0.00148242\n",
      " 0.00145177 0.00133164 0.00118979 0.00111969 0.00109558 0.00103525\n",
      " 0.00097509 0.00084759 0.00077304 0.00076734 0.00072343 0.00068274\n",
      " 0.00066685 0.0006223  0.00059208 0.00054212]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "pca = PCA()\n",
    "pca.fit(X_scaled_train)\n",
    "X_pca_train = pca.transform(X_scaled_train)\n",
    "print(pca.explained_variance_)\n",
    "print(len(pca.explained_variance_))\n",
    "print(X_pca_train.shape)\n",
    "print(type(pca.explained_variance_))\n",
    "print(pca.explained_variance_.sum())\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "n_components_pca = 0\n",
    "\n",
    "percent_contrib = 0.05\n",
    "\n",
    "for i in range(len(pca.explained_variance_)):\n",
    "    if(pca.explained_variance_ratio_[i]>=(percent_contrib/100)):\n",
    "        n_components_pca+=1\n",
    "print(\"Number of PCA components that contribute >=\",percent_contrib,\"% of variance is \",n_components_pca)\n",
    "\n",
    "pca_red = PCA(n_components=n_components_pca)\n",
    "pca_red.fit(X_scaled_train)\n",
    "X_pca_red_train = pca_red.transform(X_scaled_train)\n",
    "X_pca_red_test = pca_red.transform(X_scaled_test)\n",
    "print(pca_red.explained_variance_)\n",
    "print(len(pca_red.explained_variance_))\n",
    "print(X_pca_red_train.shape)\n",
    "print(X_pca_red_test.shape)\n",
    "print(type(pca_red.explained_variance_))\n",
    "print(pca_red.explained_variance_.sum())\n",
    "print(pca_red.explained_variance_ratio_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(377,)\n",
      "(377,)\n",
      "[0.0036658  0.22523213 0.21224566 0.05761379 0.21700188]\n",
      "[0.05 0.28 0.16 0.04 0.24]\n",
      "0.3729715158239061\n",
      "MAE  0.1027523676695448\n",
      "MSE  0.01772869889223814\n",
      "R2S  0.3729715158239061\n"
     ]
    }
   ],
   "source": [
    "clf_pca = linear_model.Lasso(alpha=0.1)\n",
    "clf_pca.fit(X_pca_red_train, y_train)\n",
    "y_pca_red_hat = clf_pca.predict(X_pca_red_test)\n",
    "print(y_pca_red_hat.shape)\n",
    "print(y_test.shape)\n",
    "print(y_pca_red_hat[0:5])\n",
    "print(y_test[0:5])\n",
    "print(clf_pca.score(X_pca_red_test,y_test))\n",
    "print(\"MAE \", mean_absolute_error(y_test, y_pca_red_hat))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE \", mean_squared_error(y_test, y_pca_red_hat))\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2S \", r2_score(y_test, y_pca_red_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013049985089977575\n",
      "[0.0043172  0.19591229 0.26606527 0.03638738 0.15470177 0.28571754\n",
      " 0.40831817 0.31874816 0.10278159 0.10788911 0.08113232 0.16930392\n",
      " 0.16354255 0.04327862 0.12340291 0.21171587 0.18266532 0.33689096\n",
      " 0.04300176 0.2034089 ]\n",
      "[0.05 0.28 0.16 0.04 0.24 0.21 0.4 0.36 0.04 0.03 0.14 0.19 0.16 0.13 0.18\n",
      " 0.36 0.05 0.52 0.02 0.09]\n",
      "MAE  0.08393899863963541\n",
      "MSE  0.013011750901331757\n",
      "R2S  0.5398004955845361\n"
     ]
    }
   ],
   "source": [
    "lasso_pca_cv = LassoCV(alphas = None, cv = 10, max_iter = 1000, random_state=1) \n",
    "lasso_pca_cv.fit(X_pca_red_train, y_train)\n",
    "print(lasso_pca_cv.alpha_)\n",
    "\n",
    "y_pca_red_hat_cv = lasso_pca_cv.predict(X_pca_red_test)\n",
    "print(y_pca_red_hat_cv[0:20])\n",
    "print(y_test[0:20])\n",
    "print(\"MAE \", mean_absolute_error(y_test, y_pca_red_hat_cv))\n",
    "print(\"MSE \", mean_squared_error(y_test, y_pca_red_hat_cv))\n",
    "print(\"R2S \", r2_score(y_test, y_pca_red_hat_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
