{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4021 - Group 4.2 \n",
    "### Project work Weeks 7-9\n",
    "\n",
    "#### Machine Learning Algorithm: Random Forests\n",
    "\n",
    "#### Dataset Information\n",
    "_Source:_ https://www.kaggle.com/shrutimehta/nasa-asteroids-classification (source: Shruti Mehta)\n",
    "\n",
    "**Content**\n",
    "The data is about Asteroids - NeoWs. NeoWs (Near Earth Object Web Service) is a RESTful web service for near earth Asteroid information. With NeoWs a user can: search for Asteroids based on their closest approach date to Earth, lookup a specific Asteroid with its NASA JPL small body id, as well as browse the overall data-set.\n",
    "\n",
    "**Acknowledgements**\n",
    "Data-set: All the data is from the (http://neo.jpl.nasa.gov/). This API is maintained by SpaceRocks Team: David Greenfield, Arezu Sarvestani, Jason English and Peter Baunach.\n",
    "\n",
    "**Inspiration**\n",
    "Finding potential hazardous and non-hazardous asteroids\n",
    "Features responsible for claiming an asteroid to be hazardous\n",
    "\n",
    "#### Notebook Structure\n",
    "1. Data Loading and Pre-processing\n",
    "2. Model training and testing\n",
    "3. Model graphing\n",
    "4. Model analysis: further eaxamination of significant features etc.\n",
    "\n",
    "#### Team Contributions:\n",
    "**Training data**\n",
    "\n",
    "29-OCT-2018 B.Parle Source data identified, loaded and initial analysis. The data field 'Hazardous' is the Classification output: i.e. Hazardous Y or N\n",
    "\n",
    "30-OCT-2018 B.Parle This article suggests SVM might be better for a binary classification problem like the one I propose: https://www.datasciencecentral.com/profiles/blogs/how-to-choose-a-machine-learning-model-some-guidelines?linkId=58574007\n",
    "\n",
    "\n",
    "**Pre-processing**\n",
    "\n",
    "31-OCT-2018 B.Parle Removed unnecessary columns and features with single values\n",
    "\n",
    "\n",
    "**Algorithm training and evaluation**\n",
    "\n",
    "30-OCT-2018 _name_ _contribution_\n",
    "\n",
    "\n",
    "\n",
    "**Visualisation of outputs**\n",
    "\n",
    "30-OCT-2018 _name_ _contribution_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4687, 30)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "#\n",
    "# 1. Dataset Loading and Pre-processing\n",
    "#\n",
    "####################\n",
    "nasa_data = pd.read_csv('nasa.csv')\n",
    "#nasa_data.head()\n",
    "nasa_data.describe()\n",
    "\n",
    "#Issues found during initial analysis that will need to be resolved:\n",
    "#1. 2 columns contain repeated data: \"Est Dia in KM(min)\", \"Est Dia in KM(max)\" \n",
    "#.  are similar to these 2 fields: \"Est Dia in M(min)\", \"Est Dia in M(max)\"\n",
    "#2. These fields are superflous: \"Est Dia in Miles(max)\",\"Est Dia in Feet(min)\"\n",
    "#3. 'object' data types that will need processing before they can be used in the learning model\n",
    "#    Objects: Close Approach Date, Orbiting Body, Orbit Determination Date, Equinox\n",
    "\n",
    "#1 and 2: drop extra columns with measurements in km, miles and inches\n",
    "nasa_data = nasa_data.drop(['Est Dia in KM(min)', 'Est Dia in KM(max)', 'Est Dia in Miles(min)', 'Est Dia in Miles(max)', 'Est Dia in Feet(min)', 'Est Dia in Feet(max)'], axis=1)\n",
    "\n",
    "#3. Object types\n",
    "\n",
    "#Close Approach Date: Drop this until we determine a use\n",
    "nasa_data = nasa_data.drop(['Close Approach Date'], axis=1)\n",
    "\n",
    "#Orbiting Body\n",
    "nasa_data['Orbiting Body'].unique()\n",
    "\n",
    "#Only 1 value in 'Orbiting body', so we can drop this column\n",
    "nasa_data = nasa_data.drop(['Orbiting Body'], axis=1)\n",
    "\n",
    "#Orbit Determination Date: Drop this until we determine a use\n",
    "nasa_data = nasa_data.drop(['Orbit Determination Date'], axis=1)\n",
    "\n",
    "#Equinox\n",
    "nasa_data['Equinox'].unique()\n",
    "\n",
    "#Only 1 value in 'Equinox', so we can drop this column\n",
    "nasa_data = nasa_data.drop(['Equinox'], axis=1)\n",
    "\n",
    "nasa_data.shape\n",
    "#30 features and 4687 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianparle/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "#\n",
    "# 1. Training\n",
    "#\n",
    "####################\n",
    "\n",
    "#Take the result vector (y) into a separate dataframe\n",
    "nasa_data_y = nasa_data.iloc[::,29]\n",
    "nasa_data_x = nasa_data.iloc[::,0:28]\n",
    "\n",
    "#nasa_data_y.head()\n",
    "#nasa_data_x.head()\n",
    "\n",
    "#Prior to training, scale the data\n",
    "nasa_data_x_scaled = preprocessing.scale(nasa_data_x)\n",
    "\n",
    "#Split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(nasa_data_x_scaled, nasa_data_y, test_size=0.6, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
